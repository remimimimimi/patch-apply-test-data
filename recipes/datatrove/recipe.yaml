context:
  name: datatrove
  version: "0.5.0"
  python_min: "3.10"

package:
  name: ${{ name|lower }}
  version: ${{ version }}

source:
  url: https://pypi.org/packages/source/${{ name[0] }}/${{ name }}/datatrove-${{ version }}.tar.gz
  sha256: b1fb13324e86126dace2de2dcaa7aeab53facfc1628f5f6e0ecf5789c78649ad
  patches:
    # Upstream issue: https://github.com/huggingface/datatrove/issues/315
    - cli.patch

build:
  number: 0
  noarch: python
  script: ${{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  python:
    entry_points:
      - check_dataset = datatrove.tools.check_dataset:main
      - merge_stats = datatrove.tools.merge_stats:main
      - launch_pickled_pipeline = datatrove.tools.launch_pickled_pipeline:main
      - failed_logs = datatrove.tools.failed_logs:main
      - inspect_data = datatrove.tools.inspect_data:main
      - jobs_status = datatrove.tools.jobs_status:main

requirements:
  host:
    - python ${{ python_min }}.*
    - setuptools
    - pip
  run:
    - python >=${{ python_min }}
    - dill >=0.3.0
    - fsspec >=2023.12.2
    - huggingface_hub >=0.17.0
    - humanize
    - loguru >=0.7.0
    - multiprocess
    - numpy >=2.0.0
    - tqdm
    - tokenizers
    - regex
    - rich

tests:
  - python:
      imports:
        - datatrove
      pip_check: true
      python_version: ${{ python_min }}.*
  - requirements:
      run:
        - python ${{ python_min }}.*
    script:
      - check_dataset --help
      - merge_stats --help
      - launch_pickled_pipeline --help
      - failed_logs --help
      - inspect_data --help
      - jobs_status --help

about:
  summary: HuggingFace library to process and filter large amounts of webdata
  license: Apache-2.0
  license_file: LICENSE
  homepage: https://github.com/huggingface/datatrove

extra:
  recipe-maintainers:
    - hadim
